## 라즈베리파이를 이용한 V4L2 영상 TCP 스트리밍 및 원격 디스플레이 프로젝트

### 1. 프로젝트 개요

#### 1.1. 프로젝트명
V4L2 및 TCP 네트워크 프로그래밍을 이용한 실시간 영상 스트리밍 시스템 구현

#### 1.2. 프로젝트 목표
본 프로젝트는 임베디드 리눅스 시스템 플랫폼 중 라즈베리파이를 활용하여 멀티미디어 데이터 처리와 네트워크 프로그래밍 기술을 융합하는 것을 목표로 함

-   **V4L2(Video for Linux 2) API** 를 사용하여 라즈베리파이에 연결된 카메라의 영상 데이터를 캡처
-   캡처한 영상 데이터를 **TCP/IP 소켓 프로그래밍** 을 통해 안정적으로 원격지에 실시간 전송
-   원격지 서버는 수신한 영상 데이터를 **리눅스 프레임버퍼(Framebuffer)** 에 직접 출력하여 실시간으로 모니터링할 수 있는 시스템 구축
-   클라이언트-서버 모델을 구현

### 2. 시스템 구성 및 아키텍처

본 시스템은 영상을 캡처하고 전송하는 **클라이언트** 와, 영상을 수신하여 화면에 출력하는 **서버** 로 구성된다.

#### 2.1. 하드웨어 구성
-   **클라이언트 (송신 측):**
    -   라즈베리파이 (Raspberry Pi 4)
    -   라즈베리파이 카메라 모듈
    -   Wi-Fi 네트워크 연결
-   **서버 (수신 및 디스플레이 측):**
    -   라즈베리파이 (Raspberry Pi 4)
    -   HDMI 디스플레이 (모니터)
    -   Wi-Fi 네트워크 연결

#### 2.2. 소프트웨어 아키텍처

1.  **클라이언트 (영상 송신):**
    -   **V4L2 API:** `/dev/video0` 디바이스를 통해 카메라 하드웨어를 제어하고, 640x480 해상도의 YUYV 포맷 영상 프레임을 지속적으로 캡처
    -   **TCP 소켓 (Client):** 지정된 서버 IP 주소와 포트로 TCP 연결
    -   **데이터 전송:** 캡처한 영상 프레임 데이터를 TCP 소켓을 통해 서버로 전송

2.  **서버 (영상 수신 및 출력):**
    -   **TCP 소켓 (Server):** 지정된 포트에서 클라이언트의 연결을 대기(`listen`, `accept`)
    -   **데이터 수신:** 연결된 클라이언트로부터 영상 프레임 데이터를 수신
    -   **YUYV to RGB565 변환:** 수신한 YUYV 컬러 포맷 데이터를 프레임버퍼가 사용하는 RGB565 포맷으로 변환
    -   **프레임버퍼 API:** `/dev/fb0` 디바이스를 메모리에 매핑(`mmap`)한 후, 변환된 RGB565 픽셀 데이터를 직접 써넣어 화면에 영상을 출력

### 3. 핵심 기술 및 구현 내용

#### 3.1. TCP 소켓을 이용한 안정적인 데이터 스트리밍
-   **문제점:** `send()`와 `recv()` 함수는 한 번의 호출로 요청한 크기의 데이터를 모두 전송/수신하는 것을 보장하지 않음. 640x480 YUYV 프레임(614,400 바이트)과 같은 대용량 데이터는 여러 번에 걸쳐 나뉘어 전송/수신될 수 있다.
-   **해결책:** `send_all()` 및 `recv_all()` 추가 함수를 사용. 이 함수들은 목표한 데이터 크기가 모두 처리될 때까지 `while` 루프를 돌며 `send()`/`recv()`를 반복 호출한다. 이를 통해 프레임 데이터가 깨지지 않고 온전하게 전송/수신되도록 보장하였다.

    ```c
    // 안정적인 데이터 수신을 위한 recv_all() 함수 예시 (서버 측)
    int recv_all(int sock, void *data, size_t len) {
        char *p = data;
        while (len > 0) {
            int received = recv(sock, p, len, 0);
            if (received <= 0) { // 연결 종료 또는 에러
                return -1;
            }
            p += received;
            len -= received;
        }
        return 0;
    }
    ```

#### 3.2. 프레임버퍼를 이용한 직접 화면 출력 (서버)

-   `open()` 함수로 프레임버퍼 디바이스(`/dev/fb0`)를 연다.
-   `ioctl()` 시스템 콜(명령: `FBIOGET_VSCREENINFO`)로 화면의 해상도, 색상 깊이(`bits_per_pixel`) 등 정보를 가져온다.
-   `mmap()` 시스템 콜을 사용하여 프레임버퍼의 물리 메모리 주소를 프로세스의 가상 메모리 공간에 매핑한다. 이를 통해 프로그램은 배열에 값을 쓰듯이 화면 메모리에 직접 접근할 수 있게 된다.
-   수신한 YUYV 데이터를 화면 출력에 적합한 **RGB565** 포맷으로 변환하는 `display_frame()` 함수를 구현하였다.

    -   **YUYV to RGB 변환:** Y(휘도), U/V(색차) 값을 표준 변환 공식에 따라 R, G, B 값으로 변환한다.
    -   **RGB to RGB565 변환:** 24비트 RGB(RGB888) 정보를 16비트 RGB565로 압축한다. 비트 시프트와 마스크 연산을 통해 Red(5비트), Green(6비트), Blue(5비트)로 데이터를 재배치한다.
        ```c
        // (R, G, B)를 16비트 pixel 값으로 변환
        uint16_t pixel = ((R & 0xF8) << 8) | ((G & 0xFC) << 3) | (B >> 3);
        ```
    -   계산된 픽셀 값을 `mmap`으로 매핑된 메모리 주소에 직접 써넣어 화면에 영상을 렌더링한다.

### 4. 실행 결과 및 결론

-   **클라이언트** 프로그램을 실행하면 카메라 영상이 성공적으로 캡처되어 지정된 IP의 서버로 전송되었다.
-   **서버** 프로그램은 클라이언트의 연결을 정상적으로 수락하였으며, 수신한 영상 데이터를 실시간으로 변환하여 모니터 화면 중앙에 끊김 없이 출력하는 것을 확인하였다.
-   `send_all` / `recv_all` 함수의 적용으로 네트워크 상태에 관계없이 안정적인 프레임 전송이 가능했다.

본 프로젝트를 통해 리눅스 시스템의 핵심적인 멀티미디어 및 네트워크 API를 실제로 제어하고, 이들을 융합한 애플리케이션을 개발하는 경험을 쌓을 수 있었다.
